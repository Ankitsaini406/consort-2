# Robots.txt for Consort Digital - Mission Critical Communications
# Generated for optimal SEO and security protection

# Allow all search engines to crawl public content
User-agent: *
Allow: /

# Block access to sensitive admin areas and development files
Disallow: /admin/
Disallow: /api/
Disallow: /_next/
Disallow: /test-results/
Disallow: /functions/
Disallow: /scripts/
Disallow: /security-tests/
Disallow: /archive/

# Block access to configuration and development files
Disallow: /*.json$
Disallow: /*.config.js$
Disallow: /*.config.ts$
Disallow: /*.env
Disallow: /.git/
Disallow: /node_modules/

# Block access to temporary and backup files
Disallow: /*~
Disallow: /*.tmp
Disallow: /*.bak
Disallow: /*.old
Disallow: /*.backup

# Block access to sensitive file types
Disallow: /*.log
Disallow: /*.sql
Disallow: /*.zip
Disallow: /*.tar.gz

# Allow crawling of essential SEO files
Allow: /sitemap.xml
Allow: /sitemap-*.xml
Allow: /favicon.ico
Allow: /favicon.svg
Allow: /robots.txt

# Allow crawling of public assets
Allow: /public/
Allow: /logos/
Allow: /icons/
Allow: /products/

# Specific rules for major search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 2

User-agent: Slurp
Allow: /
Crawl-delay: 2

# Block malicious bots and scrapers
User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: BLEXBot
Disallow: /

# Block AI training crawlers (optional - uncomment if desired)
# User-agent: GPTBot
# Disallow: /

# User-agent: ChatGPT-User
# Disallow: /

# User-agent: CCBot
# Disallow: /

# Sitemap location (add this when you create sitemap.xml)
Sitemap: https://www.consortdigital.com/sitemap.xml

# Host directive for canonical domain
Host: www.consortdigital.com 